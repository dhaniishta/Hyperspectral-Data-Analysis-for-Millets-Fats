# -*- coding: utf-8 -*-
"""regression_fatsss.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dbEcPql_yEe7zKvJMo7pmO2-_DmiDqZ5
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

millets= pd.read_csv('/content/Hyperspectral_data_millets_fat.csv')

millets.head()

millets.info()

millets.describe()

millets.columns

X= millets.iloc[:,1:169]
#X= millets.drop(['Samples', 'Carbohydrate'],axis=1)

y= millets['Fat']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42)

"""# **LINEAR REGRESSION**"""

from sklearn.linear_model import LinearRegression

lr= LinearRegression()

lr.fit(X_train, y_train)

y_pred1= lr.predict(X_test)

m1= lr.coef_
c1= lr.intercept_

m1

c1

from sklearn.metrics import mean_squared_error, r2_score

mse1= mean_squared_error(y_test, y_pred1)
r21= r2_score(y_test, y_pred1)

print('Mean Squared Error:', mse1)
print('R-squared:', r21)

"""# **RIDGE REGRESSION**"""

from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, cross_val_predict
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0]  # Adjust as needed

# Perform cross-validation
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Lists to store results
mse_scores2 = []
r2_scores2 = []
alpha_scores2 = []

for alpha in alpha_values:
    ridge = Ridge(alpha=alpha)

    # Perform cross-validation
    y_pred2 = cross_val_predict(ridge, X_scaled, y_train, cv=cv)

    # Calculate MSE and R^2
    mse = mean_squared_error(y_train, y_pred2)
    r2 = r2_score(y_train, y_pred2)

    # Store scores
    mse_scores2.append(mse)
    r2_scores2.append(r2)
    alpha_scores2.append(alpha)

    print(f'Alpha: {alpha}, MSE: {mse}, R^2: {r2}')

optimal_index = np.argmin(mse_scores2)
optimal_alpha = alpha_scores2[optimal_index]
min_mse = np.min(mse_scores2)
optimal_r2 = r2_scores2[optimal_index]
print(f'Optimal alpha: {optimal_alpha} with MSE: {min_mse}, R^2: {optimal_r2}')

# Optionally, fit a final Ridge model with the optimal alpha
ridge_optimal = Ridge(alpha=optimal_alpha)
ridge_optimal.fit(X_scaled, y_train)

m2= ridge_optimal.coef_
c2= ridge_optimal.intercept_

m2

c2

"""# **LASSO REGRESSION**"""

from sklearn.linear_model import Lasso

alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0]  # Adjust as needed

# Perform cross-validation
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Lists to store results
mse_scores3 = []
r2_scores3 = []
alpha_scores3 = []

for alpha in alpha_values:
    lasso = Lasso(alpha=alpha)

    # Perform cross-validation
    y_pred_cv = cross_val_predict(lasso, X_scaled, y_train, cv=cv)

    # Calculate MSE
    mse = mean_squared_error(y_train, y_pred_cv)
    r2 = r2_score(y_train, y_pred_cv)

    # Store scores
    mse_scores3.append(mse)
    r2_scores3.append(mse)
    alpha_scores3.append(alpha)

    print(f"Alpha: {alpha}, MSE: {mse}, r2: {r2}")

optimal_index = np.argmin(mse_scores3)
optimal_alpha = alpha_scores3[optimal_index]
min_mse = mse_scores3[optimal_index]
optimal_r2 = r2_scores3[optimal_index]
print(f'Optimal alpha: {optimal_alpha} with MSE: {min_mse}, R^2: {optimal_r2}')

# Optionally, fit a final Lasso model with the optimal alpha
lasso_optimal = Lasso(alpha=optimal_alpha)
lasso_optimal.fit(X_scaled, y_train)

m3= lasso_optimal.coef_
c3= lasso_optimal.intercept_

m3

c3

"""# **ELASTIC NET REGRESSION**"""

from sklearn.linear_model import ElasticNet

alpha_values = [0.001, 0.01, 0.1, 1.0, 10.0]  # Adjust as needed

# Range of l1_ratio values to test
l1_ratio_values = [0.1, 0.3, 0.5, 0.7, 0.9]  # Adjust as needed

# Perform cross-validation
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Lists to store results
mse_scores4 = []
r2_scores4 = []
alpha_scores4 = []
l1_ratio_scores4 = []

for alpha in alpha_values:
    for l1_ratio in l1_ratio_values:
        elastic_net = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)

        # Perform cross-validation
        y_pred4 = cross_val_predict(elastic_net, X_scaled, y_train, cv=cv)

        # Calculate MSE and R^2
        mse = mean_squared_error(y_train, y_pred4)
        r2 = r2_score(y_train, y_pred4)

        # Store scores
        mse_scores4.append(mse)
        r2_scores4.append(r2)
        alpha_scores4.append(alpha)
        l1_ratio_scores4.append(l1_ratio)

        print(f"Alpha: {alpha}, L1 Ratio: {l1_ratio}, MSE: {mse}, R^2: {r2}")

optimal_index = np.argmin(mse_scores4)
optimal_alpha = alpha_scores4[optimal_index]
optimal_l1_ratio = l1_ratio_scores4[optimal_index]
min_mse = np.min(mse_scores4)
optimal_r2 = r2_scores4[optimal_index]
print(f'\nOptimal alpha: {optimal_alpha}, Optimal L1 Ratio: {optimal_l1_ratio}')
print(f'Optimal MSE: {min_mse}, Optimal R^2: {optimal_r2}')

# Optionally, fit a final Elastic Net model with the optimal alpha and l1_ratio
elastic_net_optimal = ElasticNet(alpha=optimal_alpha, l1_ratio=optimal_l1_ratio)
elastic_net_optimal.fit(X_scaled, y_train)

m4= elastic_net_optimal.coef_
c4= elastic_net_optimal.intercept_

m4

c4

"""# **PLSR**"""

from sklearn.cross_decomposition import PLSRegression
from sklearn.decomposition import PCA

n_components_range = range(1, min(X.shape[0], X.shape[1]) + 1) # Adjust upper bound as needed

# Perform cross-validation
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Lists to store results
mse_scores5 = []
r2_scores5 = []

for n_components in n_components_range:
    # Create PCA pipeline
    pca = PCA(n_components=n_components)

    # Fit and transform data with PCA
    X_pca = pca.fit_transform(X_scaled)

    # Initialize PLSRegression model
    plsr = PLSRegression(n_components=n_components)

    # Perform cross-validation
    y_pred = cross_val_predict(plsr, X_pca, y_train, cv=cv)

    # Calculate metrics
    mse = mean_squared_error(y_train, y_pred)
    r2 = r2_score(y_train, y_pred)

    # Store scores
    mse_scores5.append(mse)
    r2_scores5.append(r2)

    print(f"Number of PCA components: {n_components}, MSE: {mse}, R^2: {r2}")

# Find the optimal number of components
optimal_index = np.argmin(mse_scores5)  # Index with minimum MSE
optimal_n_components = n_components_range[optimal_index]
min_mse = np.min(mse_scores5)
optimal_r2 = r2_scores5[optimal_index]

print(f'\nOptimal number of PCA components: {optimal_n_components} with MSE: {min_mse} with R2 score: {optimal_r2}')

optimal_index = np.argmin(mse_scores5)
optimal_n_components = n_components_range[optimal_index]
min_mse = np.min(mse_scores5)
optimal_r2 = r2_scores5[optimal_index]
print(f'\nOptimal number of components: {optimal_n_components} with MSE: {min_mse} with R2 score: {optimal_r2}')

# Optionally, fit a final PLSR model with the optimal number of components
plsr_optimal = PLSRegression(n_components=optimal_n_components)
plsr_optimal.fit(X_scaled, y_train)

m5= plsr_optimal.coef_
c5= plsr_optimal.intercept_

m5

c5

"""# **SVR**"""

from sklearn.svm import SVR

C_range = [0.1, 1.0, 10.0]  # Example values for C
epsilon_range = [0.01, 0.1, 1.0]  # Example values for epsilon

# Perform cross-validation
k_folds = 5
cv = KFold(n_splits=k_folds, shuffle=True, random_state=42)

# Lists to store results
mse_scores6 = np.zeros((len(C_range), len(epsilon_range)))
r2_scores6 = np.zeros((len(C_range), len(epsilon_range)))

# Perform cross-validation for different parameters
for i, C in enumerate(C_range):
    for j, epsilon in enumerate(epsilon_range):
        svr = SVR(kernel='rbf', C=C, epsilon=epsilon)

        # Perform cross-validation
        y_pred = cross_val_predict(svr, X_scaled, y_train, cv=cv)

        # Calculate metrics
        mse = mean_squared_error(y_train, y_pred)
        r2 = r2_score(y_train, y_pred)

        # Store scores
        mse_scores6[i, j] = mse
        r2_scores6[i, j] = r2

        print(f"C: {C}, Epsilon: {epsilon}, MSE: {mse}, R^2: {r2}")

optimal_idx = np.unravel_index(np.argmin(mse_scores6, axis=None), mse_scores6.shape)
optimal_C = C_range[optimal_idx[0]]
optimal_epsilon = epsilon_range[optimal_idx[1]]
min_mse = np.min(mse_scores6)
optimal_r2 = r2_scores6[optimal_idx[0], optimal_idx[1]]

print(f"\nOptimal parameters: C = {optimal_C}, Epsilon = {optimal_epsilon}")
print(f"Minimum MSE: {min_mse}")
print(f"Corresponding R^2 score: {optimal_r2}")

svr_optimal = SVR(kernel='rbf', C=optimal_C, epsilon=optimal_epsilon)
svr_optimal.fit(X_scaled, y_train)

m6= svr_optimal.dual_coef_
c6= svr_optimal.intercept_

m6

c6

plt.plot(mse1, r21, '-o', color='red') #linear regression
plt.plot(mse_scores2, r2_scores2, '-o', color='blue') #ridge ression
#plt.plot(mse_scores3, r2_scores3, '-o', color='orange') #lasso regression
plt.plot(mse_scores4, r2_scores4, '-o', color='purple') #elastic net regression
plt.plot(mse_scores5, r2_scores5, '-o',color='violet') #plsr
plt.plot(mse_scores6, r2_scores6, '-o',color='green') #svr
plt.ylabel('R-squared')
plt.xlabel('Mean Squared Error')
plt.title('Regression Performance')
plt.legend(['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Elastic Net Regression', 'SVR'])
plt.grid(True)
plt.show()

